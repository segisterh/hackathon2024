{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 19 18:29:14 2024\n",
    "\n",
    "@author: l00416959\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "cfg_path = '../Dataset0/Dataset0CfgData1.txt'\n",
    "inputdata_path = '../Dataset0/Dataset0InputData1.txt'\n",
    "\n",
    "# func to read in slices\n",
    "def read_slice_of_file(file_path, start, end):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # use itertools.islice to get slices\n",
    "        slice_lines = list(itertools.islice(file, start, end))\n",
    "    return slice_lines\n",
    "\n",
    "# read RoundYCfgDataX.txt \n",
    "slice_lines = read_slice_of_file(cfg_path, 1, 6)\n",
    "info = np.loadtxt(slice_lines)\n",
    "tol_samp_num = int(info[0])\n",
    "port_num = int(info[2])\n",
    "ant_num = int(info[3])\n",
    "sc_num = int(info[4])\n",
    "\n",
    "# read RoundYInputDataX. in slices \n",
    "H = []\n",
    "slice_samp_num = 1000   #number of samples\n",
    "slice_num = int(tol_samp_num / slice_samp_num) #number of slices\n",
    "for slice_idx in range(slice_num):\n",
    "    print(slice_idx)\n",
    "    slice_lines = read_slice_of_file(inputdata_path, slice_idx * slice_samp_num, (slice_idx + 1) * slice_samp_num)\n",
    "    Htmp = np.loadtxt(slice_lines)\n",
    "    Htmp = np.reshape(Htmp, (slice_samp_num, 2, sc_num, ant_num, port_num))\n",
    "    Htmp = Htmp[:, 0, :, :, :] + 1j*Htmp[:, 1, :, :, :]\n",
    "    Htmp = np.transpose(Htmp, (0,3,2,1))\n",
    "    \n",
    "    if np.size(H) == 0:\n",
    "        H = Htmp\n",
    "    else:\n",
    "        H = np.concatenate((H, Htmp), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "2\n",
      "64\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(np.size(H, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(H[0, 0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.complex128(0.734228+0.770911j)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.734228+0.770911j  1.256584-0.088519j  0.553896-1.088371j ...\n",
      "    0.066881+1.217681j  1.111822+0.595838j  0.98297 -0.408424j]\n",
      "  [ 0.781669+0.652409j  1.038199+0.020232j  0.749548-0.974443j ...\n",
      "    0.025998+0.994898j  0.922855+0.757614j  1.112302-0.401542j]\n",
      "  [ 0.827215+0.791147j  0.943926-0.076186j  0.750974-0.716739j ...\n",
      "    0.137272+0.976557j  0.705829+0.680568j  1.161513-0.168052j]\n",
      "  ...\n",
      "  [-0.335698+0.27306j   0.109357+0.469059j  0.337797+0.137317j ...\n",
      "   -0.473159+0.072984j -0.141195+0.365209j  0.067999+0.326774j]\n",
      "  [-0.278269+0.152633j -0.09328 +0.435103j  0.350276+0.257186j ...\n",
      "   -0.408211-0.087382j -0.280637+0.363858j  0.106142+0.326327j]\n",
      "  [-0.246592+0.179119j -0.151702+0.283239j  0.218753+0.372924j ...\n",
      "   -0.273529-0.131017j -0.384274+0.181545j  0.015319+0.41183j ]]\n",
      "\n",
      " [[ 0.893547+0.618462j  0.901772-0.309352j  0.459753-0.789159j ...\n",
      "    0.334546+0.927889j  0.78556 +0.408464j  0.965627-0.322806j]\n",
      "  [ 0.742873+0.778431j  1.089285-0.212112j  0.453431-0.846259j ...\n",
      "    0.199337+1.118676j  0.906045+0.437229j  0.917894-0.25935j ]\n",
      "  [ 0.661696+0.731316j  1.135404-0.02732j   0.583699-0.964263j ...\n",
      "    0.001898+1.100153j  0.967489+0.62162j   0.94913 -0.325056j]\n",
      "  ...\n",
      "  [ 0.409249-0.638244j -0.148155-0.594435j -0.548301-0.418727j ...\n",
      "    0.599724-0.20184j   0.378958-0.52692j  -0.255708-0.748618j]\n",
      "  [ 0.573854-0.622356j -0.229761-0.757244j -0.576655-0.323492j ...\n",
      "    0.80085 -0.224469j  0.296106-0.606877j -0.158904-0.72531j ]\n",
      "  [ 0.574612-0.552688j -0.141202-0.918561j -0.773929-0.335497j ...\n",
      "    0.901198-0.114695j  0.343223-0.802445j -0.275755-0.675613j]]]\n"
     ]
    }
   ],
   "source": [
    "print(H[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(H, n_components=50):\n",
    "    \"\"\"\n",
    "    Extract spatial and frequency features from the complex channel matrix H using Complex PCA.\n",
    "    \n",
    "    Parameters:\n",
    "        H (numpy.ndarray): Complex channel matrix with shape (samples, 64, 2, 408).\n",
    "        n_components (int): Number of dimensions to reduce to using PCA.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Reduced feature representation (samples, n_components).\n",
    "    \"\"\"\n",
    "    num_samples, num_antennas, num_user_antennas, num_subcarriers = H.shape\n",
    "\n",
    "    # Step 1: Compute spatial covariance matrix\n",
    "    spatial_features = []\n",
    "    for sample in H:\n",
    "        # Combine user antenna dimensions into a single matrix (64, 816)\n",
    "        reshaped_sample = sample.reshape(num_antennas, -1)  # Shape: (64, 816)\n",
    "        # Compute spatial covariance (64x64)\n",
    "        spatial_cov = np.matmul(reshaped_sample, reshaped_sample.conj().T)\n",
    "        spatial_features.append(spatial_cov.flatten())  # Flatten into 1D array\n",
    "\n",
    "    spatial_features = np.array(spatial_features)  # Shape: (samples, 64*64)\n",
    "\n",
    "    # Step 2: Compute frequency domain features\n",
    "    frequency_features = []\n",
    "    for sample in H:\n",
    "        # Average across antennas and user antennas for each subcarrier (408)\n",
    "        freq_avg = np.mean(np.abs(sample), axis=(0, 1))  # Shape: (408,)\n",
    "        frequency_features.append(freq_avg)\n",
    "\n",
    "    frequency_features = np.array(frequency_features)  # Shape: (samples, 408)\n",
    "\n",
    "    # Step 3: Combine spatial and frequency features\n",
    "    combined_features = np.hstack((spatial_features, frequency_features))  # Shape: (samples, 64*64 + 408)\n",
    "\n",
    "    # Step 4: Apply Complex PCA for dimensionality reduction\n",
    "    # Compute covariance matrix of the combined features\n",
    "    cov_matrix = np.cov(combined_features.T)  # Shape: (features, features)\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    # Sort by eigenvalues in descending order\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    # Select the top n_components eigenvectors\n",
    "    principal_components = eigenvectors[:, :n_components]  # Shape: (features, n_components)\n",
    "    # Project data onto the principal components\n",
    "    reduced_features = np.dot(combined_features, principal_components)  # Shape: (samples, n_components)\n",
    "\n",
    "    return reduced_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reduced = extract_features(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_real_amplitude_phase(H):\n",
    "    \"\"\"\n",
    "    Convert complex data to a real-valued matrix using amplitude and phase.\n",
    "    \n",
    "    Parameters:\n",
    "        H (numpy.ndarray): Complex-valued matrix with shape (samples, features).\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Real-valued matrix with shape (samples, features * 2).\n",
    "    \"\"\"\n",
    "    amplitude = np.abs(H)  # 振幅\n",
    "    phase = np.angle(H)    # 相位\n",
    "    return np.hstack((amplitude, phase))\n",
    "\n",
    "# 使用示例\n",
    "real_features = convert_to_real_amplitude_phase(test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix_in_batches(features, batch_size=1000):\n",
    "    \"\"\"\n",
    "    分批次计算距离矩阵，以节省内存。\n",
    "    \n",
    "    Parameters:\n",
    "        features (numpy.ndarray): 高维特征矩阵，形状为 (samples, n_features)。\n",
    "        batch_size (int): 每个批次的大小，用于控制内存使用。\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: 计算后的距离矩阵，形状为 (samples, samples)。\n",
    "    \"\"\"\n",
    "    n_samples = features.shape[0]\n",
    "    distance_matrix = np.zeros((n_samples, n_samples), dtype=np.float64)\n",
    "\n",
    "    # 逐块计算距离\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        end_i = min(i + batch_size, n_samples)\n",
    "        for j in range(0, n_samples, batch_size):\n",
    "            end_j = min(j + batch_size, n_samples)\n",
    "            # 计算 i 和 j 块之间的距离\n",
    "            block_distances = np.linalg.norm(features[i:end_i, np.newaxis] - features[j:end_j], axis=2)\n",
    "            distance_matrix[i:end_i, j:end_j] = block_distances\n",
    "\n",
    "    return distance_matrix\n",
    "\n",
    "def reduce_dimension_mds(features, n_components=2, batch_size=1000):\n",
    "    # 计算距离矩阵\n",
    "    distance_matrix = compute_distance_matrix_in_batches(features, batch_size=batch_size)\n",
    "\n",
    "    # 使用 MDS 降维\n",
    "    mds = MDS(n_components=n_components, dissimilarity=\"precomputed\", random_state=0)\n",
    "    low_dim_coords = mds.fit_transform(distance_matrix)\n",
    "    \n",
    "    return low_dim_coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m low_dim_coords \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_dimension_mds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mreduce_dimension_mds\u001b[0;34m(features, n_components, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 使用 MDS 降维\u001b[39;00m\n\u001b[1;32m     31\u001b[0m mds \u001b[38;5;241m=\u001b[39m MDS(n_components\u001b[38;5;241m=\u001b[39mn_components, dissimilarity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m low_dim_coords \u001b[38;5;241m=\u001b[39m \u001b[43mmds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m low_dim_coords\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_mds.py:641\u001b[0m, in \u001b[0;36mMDS.fit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdissimilarity \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdissimilarity_matrix_ \u001b[38;5;241m=\u001b[39m euclidean_distances(X)\n\u001b[0;32m--> 641\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstress_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msmacof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdissimilarity_matrix_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalized_stress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_stress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_mds.py:352\u001b[0m, in \u001b[0;36msmacof\u001b[0;34m(dissimilarities, metric, n_components, init, n_init, n_jobs, max_iter, verbose, eps, random_state, return_n_iter, normalized_stress)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_init):\n\u001b[0;32m--> 352\u001b[0m         pos, stress, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_smacof_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdissimilarities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnormalized_stress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_stress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m best_stress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m stress \u001b[38;5;241m<\u001b[39m best_stress:\n\u001b[1;32m    364\u001b[0m             best_stress \u001b[38;5;241m=\u001b[39m stress\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_mds.py:128\u001b[0m, in \u001b[0;36m_smacof_single\u001b[0;34m(dissimilarities, metric, n_components, init, max_iter, verbose, eps, random_state, normalized_stress)\u001b[0m\n\u001b[1;32m    125\u001b[0m ir \u001b[38;5;241m=\u001b[39m IsotonicRegression()\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Compute distance and monotonic regression\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     dis \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metric:\n\u001b[1;32m    131\u001b[0m         disparities \u001b[38;5;241m=\u001b[39m dissimilarities\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:372\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    368\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m         )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:410\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    408\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    409\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n\u001b[0;32m--> 410\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "low_dim_coords = reduce_dimension_mds(real_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "import numpy as np\n",
    "\n",
    "def complex_to_real_matrix(H):\n",
    "    \"\"\"\n",
    "    Convert a complex matrix into a doubled real-valued matrix.\n",
    "    Parameters:\n",
    "        H (numpy.ndarray): Complex-valued input matrix.\n",
    "    Returns:\n",
    "        numpy.ndarray: Real-valued doubled matrix.\n",
    "    \"\"\"\n",
    "    real_part = np.real(H)\n",
    "    imag_part = np.imag(H)\n",
    "    H_real = np.block([\n",
    "        [real_part, -imag_part],\n",
    "        [imag_part, real_part]\n",
    "    ])\n",
    "    return H_real\n",
    "\n",
    "def extract_features(H):\n",
    "    \"\"\"\n",
    "    Extract spatial and frequency features from the channel matrix H.\n",
    "    Parameters:\n",
    "        H (numpy.ndarray): Channel matrix with shape (samples, 64, 2, 408)\n",
    "    Returns:\n",
    "        numpy.ndarray: Reduced feature representation (samples, reduced_dim)\n",
    "    \"\"\"\n",
    "    num_samples, num_antennas, num_user_antennas, num_subcarriers = H.shape\n",
    "\n",
    "    # Step 1: Compute spatial covariance matrix\n",
    "    spatial_features = []\n",
    "    for sample in H:\n",
    "        # Combine user antenna dimensions into a single matrix (64, 816)\n",
    "        reshaped_sample = sample.reshape(num_antennas, -1)\n",
    "        # Compute spatial covariance (64x64)\n",
    "        spatial_cov = np.matmul(reshaped_sample, reshaped_sample.conj().T)\n",
    "        # Flatten spatial covariance matrix to get the spatial features\n",
    "        spatial_features.append(spatial_cov.flatten())  # Or use PCA here\n",
    "\n",
    "    spatial_features = np.array(spatial_features)\n",
    "\n",
    "    # Step 2: Compute frequency domain features\n",
    "    frequency_features = []\n",
    "    for sample in H:\n",
    "        # Average across antennas and user antennas for each subcarrier (408)\n",
    "        freq_avg = np.mean(np.abs(sample), axis=(0, 1))\n",
    "        frequency_features.append(freq_avg)\n",
    "\n",
    "    frequency_features = np.array(frequency_features)\n",
    "\n",
    "    # Step 3: Combine spatial and frequency features\n",
    "    combined_features = np.hstack((spatial_features, frequency_features))\n",
    "\n",
    "    # Step 4: Convert the combined features to real-valued matrix for SVD\n",
    "    combined_features_real = complex_to_real_matrix(combined_features)\n",
    "\n",
    "    # Step 5: Apply Randomized SVD for dimensionality reduction\n",
    "    U, Sigma, VT = randomized_svd(combined_features_real, n_components=50, random_state=42)\n",
    "\n",
    "    # Step 6: Reconstruct reduced features using U and Sigma\n",
    "    reduced_features = np.dot(U, np.diag(Sigma))\n",
    "\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_reduced = extract_features(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def complex_tsne(H, n_components=2):\n",
    "    \"\"\"\n",
    "    Apply t-SNE for dimensionality reduction on complex data.\n",
    "    Parameters:\n",
    "        H (numpy.ndarray): Complex-valued input data of shape (samples, 64, 2, 408).\n",
    "        n_components (int): Number of components to retain (typically 2 for 2D visualization).\n",
    "    Returns:\n",
    "        numpy.ndarray: Reduced feature representation (samples, n_components).\n",
    "    \"\"\"\n",
    "    # Step 1: Reshape the complex data into a 2D matrix\n",
    "    num_samples, num_antennas, num_user_antennas, num_subcarriers = H.shape\n",
    "    reshaped_H = H.reshape(num_samples, -1)  # Reshape to (samples, 64*2*408)\n",
    "\n",
    "    # Step 2: Convert the complex data into real-valued data by separating real and imaginary parts\n",
    "    # Concatenate real and imaginary parts of H to form a real-valued matrix\n",
    "    real_part = np.real(reshaped_H)\n",
    "    imag_part = np.imag(reshaped_H)\n",
    "    combined_real_data = np.concatenate((real_part, imag_part), axis=1)  # Shape: (samples, 2*64*2*408)\n",
    "\n",
    "    # Step 3: Apply t-SNE for dimensionality reduction\n",
    "    # We use TSNE to reduce the dimensionality while preserving the structure of the data\n",
    "    tsne = TSNE(n_components=n_components, random_state=42)\n",
    "    reduced_features = tsne.fit_transform(combined_real_data)\n",
    "\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test3 = complex_tsne(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
